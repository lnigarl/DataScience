{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled71.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNd0sX+gyBLjWVgkAVTlDF4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogut77/DataScience/blob/main/BoostingClassifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IrgV4xyWYWoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for Jupyter-book, we copy data from GitHub, locally, to save Internet traffic,\n",
        "# you can specify the data/ folder from the root of your cloned\n",
        "# https://github.com/Yorko/mlcourse.ai repo, to save Internet traffic\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "from matplotlib import pyplot as plt\n",
        "DATA_PATH = \"https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/\"\n",
        "df = pd.read_csv(DATA_PATH + \"telecom_churn.csv\")\n",
        "\n",
        "df[\"International plan\"] = pd.factorize(df[\"International plan\"])[0]\n",
        "df[\"Voice mail plan\"] = pd.factorize(df[\"Voice mail plan\"])[0]\n",
        "df[\"Churn\"] = df[\"Churn\"].astype(\"int\")\n",
        "states = df[\"State\"]\n",
        "y = df[\"Churn\"]\n",
        "X=df.drop([\"State\", \"Churn\"], axis=1)\n"
      ],
      "metadata": {
        "id": "EZdL1N4MZqZF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "hm9ZMVW9aJNh",
        "outputId": "96321484-918d-4f6b-9616-a56373e93df5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Account length  Area code  International plan  Voice mail plan  \\\n",
              "0                128        415                   0                0   \n",
              "1                107        415                   0                0   \n",
              "2                137        415                   0                1   \n",
              "3                 84        408                   1                1   \n",
              "4                 75        415                   1                1   \n",
              "...              ...        ...                 ...              ...   \n",
              "3328             192        415                   0                0   \n",
              "3329              68        415                   0                1   \n",
              "3330              28        510                   0                1   \n",
              "3331             184        510                   1                1   \n",
              "3332              74        415                   0                0   \n",
              "\n",
              "      Number vmail messages  Total day minutes  Total day calls  \\\n",
              "0                        25              265.1              110   \n",
              "1                        26              161.6              123   \n",
              "2                         0              243.4              114   \n",
              "3                         0              299.4               71   \n",
              "4                         0              166.7              113   \n",
              "...                     ...                ...              ...   \n",
              "3328                     36              156.2               77   \n",
              "3329                      0              231.1               57   \n",
              "3330                      0              180.8              109   \n",
              "3331                      0              213.8              105   \n",
              "3332                     25              234.4              113   \n",
              "\n",
              "      Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
              "0                45.07              197.4               99             16.78   \n",
              "1                27.47              195.5              103             16.62   \n",
              "2                41.38              121.2              110             10.30   \n",
              "3                50.90               61.9               88              5.26   \n",
              "4                28.34              148.3              122             12.61   \n",
              "...                ...                ...              ...               ...   \n",
              "3328             26.55              215.5              126             18.32   \n",
              "3329             39.29              153.4               55             13.04   \n",
              "3330             30.74              288.8               58             24.55   \n",
              "3331             36.35              159.6               84             13.57   \n",
              "3332             39.85              265.9               82             22.60   \n",
              "\n",
              "      Total night minutes  Total night calls  Total night charge  \\\n",
              "0                   244.7                 91               11.01   \n",
              "1                   254.4                103               11.45   \n",
              "2                   162.6                104                7.32   \n",
              "3                   196.9                 89                8.86   \n",
              "4                   186.9                121                8.41   \n",
              "...                   ...                ...                 ...   \n",
              "3328                279.1                 83               12.56   \n",
              "3329                191.3                123                8.61   \n",
              "3330                191.9                 91                8.64   \n",
              "3331                139.2                137                6.26   \n",
              "3332                241.4                 77               10.86   \n",
              "\n",
              "      Total intl minutes  Total intl calls  Total intl charge  \\\n",
              "0                   10.0                 3               2.70   \n",
              "1                   13.7                 3               3.70   \n",
              "2                   12.2                 5               3.29   \n",
              "3                    6.6                 7               1.78   \n",
              "4                   10.1                 3               2.73   \n",
              "...                  ...               ...                ...   \n",
              "3328                 9.9                 6               2.67   \n",
              "3329                 9.6                 4               2.59   \n",
              "3330                14.1                 6               3.81   \n",
              "3331                 5.0                10               1.35   \n",
              "3332                13.7                 4               3.70   \n",
              "\n",
              "      Customer service calls  \n",
              "0                          1  \n",
              "1                          1  \n",
              "2                          0  \n",
              "3                          2  \n",
              "4                          3  \n",
              "...                      ...  \n",
              "3328                       2  \n",
              "3329                       3  \n",
              "3330                       2  \n",
              "3331                       2  \n",
              "3332                       0  \n",
              "\n",
              "[3333 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8513e3e0-ad7b-4354-bff9-cfd5a52edc7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Account length</th>\n",
              "      <th>Area code</th>\n",
              "      <th>International plan</th>\n",
              "      <th>Voice mail plan</th>\n",
              "      <th>Number vmail messages</th>\n",
              "      <th>Total day minutes</th>\n",
              "      <th>Total day calls</th>\n",
              "      <th>Total day charge</th>\n",
              "      <th>Total eve minutes</th>\n",
              "      <th>Total eve calls</th>\n",
              "      <th>Total eve charge</th>\n",
              "      <th>Total night minutes</th>\n",
              "      <th>Total night calls</th>\n",
              "      <th>Total night charge</th>\n",
              "      <th>Total intl minutes</th>\n",
              "      <th>Total intl calls</th>\n",
              "      <th>Total intl charge</th>\n",
              "      <th>Customer service calls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>45.07</td>\n",
              "      <td>197.4</td>\n",
              "      <td>99</td>\n",
              "      <td>16.78</td>\n",
              "      <td>244.7</td>\n",
              "      <td>91</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>107</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>27.47</td>\n",
              "      <td>195.5</td>\n",
              "      <td>103</td>\n",
              "      <td>16.62</td>\n",
              "      <td>254.4</td>\n",
              "      <td>103</td>\n",
              "      <td>11.45</td>\n",
              "      <td>13.7</td>\n",
              "      <td>3</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>137</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>41.38</td>\n",
              "      <td>121.2</td>\n",
              "      <td>110</td>\n",
              "      <td>10.30</td>\n",
              "      <td>162.6</td>\n",
              "      <td>104</td>\n",
              "      <td>7.32</td>\n",
              "      <td>12.2</td>\n",
              "      <td>5</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84</td>\n",
              "      <td>408</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>50.90</td>\n",
              "      <td>61.9</td>\n",
              "      <td>88</td>\n",
              "      <td>5.26</td>\n",
              "      <td>196.9</td>\n",
              "      <td>89</td>\n",
              "      <td>8.86</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75</td>\n",
              "      <td>415</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>28.34</td>\n",
              "      <td>148.3</td>\n",
              "      <td>122</td>\n",
              "      <td>12.61</td>\n",
              "      <td>186.9</td>\n",
              "      <td>121</td>\n",
              "      <td>8.41</td>\n",
              "      <td>10.1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.73</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3328</th>\n",
              "      <td>192</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>156.2</td>\n",
              "      <td>77</td>\n",
              "      <td>26.55</td>\n",
              "      <td>215.5</td>\n",
              "      <td>126</td>\n",
              "      <td>18.32</td>\n",
              "      <td>279.1</td>\n",
              "      <td>83</td>\n",
              "      <td>12.56</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "      <td>2.67</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3329</th>\n",
              "      <td>68</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>231.1</td>\n",
              "      <td>57</td>\n",
              "      <td>39.29</td>\n",
              "      <td>153.4</td>\n",
              "      <td>55</td>\n",
              "      <td>13.04</td>\n",
              "      <td>191.3</td>\n",
              "      <td>123</td>\n",
              "      <td>8.61</td>\n",
              "      <td>9.6</td>\n",
              "      <td>4</td>\n",
              "      <td>2.59</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3330</th>\n",
              "      <td>28</td>\n",
              "      <td>510</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>180.8</td>\n",
              "      <td>109</td>\n",
              "      <td>30.74</td>\n",
              "      <td>288.8</td>\n",
              "      <td>58</td>\n",
              "      <td>24.55</td>\n",
              "      <td>191.9</td>\n",
              "      <td>91</td>\n",
              "      <td>8.64</td>\n",
              "      <td>14.1</td>\n",
              "      <td>6</td>\n",
              "      <td>3.81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>184</td>\n",
              "      <td>510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>213.8</td>\n",
              "      <td>105</td>\n",
              "      <td>36.35</td>\n",
              "      <td>159.6</td>\n",
              "      <td>84</td>\n",
              "      <td>13.57</td>\n",
              "      <td>139.2</td>\n",
              "      <td>137</td>\n",
              "      <td>6.26</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>74</td>\n",
              "      <td>415</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>234.4</td>\n",
              "      <td>113</td>\n",
              "      <td>39.85</td>\n",
              "      <td>265.9</td>\n",
              "      <td>82</td>\n",
              "      <td>22.60</td>\n",
              "      <td>241.4</td>\n",
              "      <td>77</td>\n",
              "      <td>10.86</td>\n",
              "      <td>13.7</td>\n",
              "      <td>4</td>\n",
              "      <td>3.70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3333 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8513e3e0-ad7b-4354-bff9-cfd5a52edc7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8513e3e0-ad7b-4354-bff9-cfd5a52edc7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8513e3e0-ad7b-4354-bff9-cfd5a52edc7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=17\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "aC4sGAvybIGe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decison Tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "tree = DecisionTreeClassifier(random_state=17)\n",
        "tree.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "tree_pred = tree.predict(X_test)\n",
        "accuracy_score(y_test, tree_pred) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caDTFnXIb9Kn",
        "outputId": "ccc3cdf0-85c3-427d-be87-b5506abafa86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(random_state=17 )\n",
        "forest.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "forest_pred = forest.predict(X_test)\n",
        "accuracy_score(y_test, forest_pred) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqqgQ351dStx",
        "outputId": "691e3adb-d3bb-447b-dcb2-e9a8c75c476e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(random_state=17)\n",
        "model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "xgb_pred = model.predict(X_test)\n",
        "accuracy_score(y_test, xgb_pred)"
      ],
      "metadata": {
        "id": "g5ar8WG6-q_4",
        "outputId": "c0b8bafa-821e-4a2c-fe7b-610ae7988e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.951"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Light GBM\n",
        "import lightgbm as lgb\n",
        "lgb_model = lgb.LGBMClassifier(random_state=17)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "accuracy_score(y_test, lgb_model.predict(X_test))"
      ],
      "metadata": {
        "id": "sDYQOsNJClI6",
        "outputId": "6518b4be-baef-4182-ce55-fbd5e6ee7208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.956"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbm_model = GradientBoostingClassifier(random_state=17)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "accuracy_score(y_test, gbm_model.predict(X_test))"
      ],
      "metadata": {
        "id": "7uzEf6HPB8q4",
        "outputId": "264d7adb-3a87-488c-8575-c9579eb67ea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.954"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ada Boost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada = AdaBoostClassifier(random_state=17)\n",
        "ada.fit(X_train, y_train)\n",
        "accuracy_score(y_test, ada.predict(X_test))"
      ],
      "metadata": {
        "id": "JR2Z8O8EYi0N",
        "outputId": "ea9729d0-5536-4b23-8146-5ba67c609235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.874"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest CV\n",
        "from time import time\n",
        "t0=time()\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "forest_params = {\"max_depth\": range(5, X_train.shape[1],3), \"max_features\": range(5, X_train.shape[1],3)}\n",
        "forest = RandomForestClassifier(random_state=17 )\n",
        "forest_grid = GridSearchCV(forest, forest_params, cv=3, n_jobs=-1, verbose=True)\n",
        "forest_grid.fit(X_train, y_train)\n",
        "forest_grid.best_params_, forest_grid.best_score_\n",
        "print(accuracy_score(y_test, forest_grid.predict(X_test)))\n",
        "print(forest_grid.best_params_, forest_grid.best_score_)\n",
        "t1=time()\n",
        "print('Time is ' +str(t1-t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1leXRk6O-Hm",
        "outputId": "db7c2c34-505c-4474-b9ee-8d88a2aedaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
            "0.954\n",
            "{'max_depth': 17, 'max_features': 8} 0.946421265187332\n",
            "Time is 41.70181083679199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost CV"
      ],
      "metadata": {
        "id": "O1X3UbjSfNGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Light GBM CV"
      ],
      "metadata": {
        "id": "vDoJ0GG2fWg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Based CV"
      ],
      "metadata": {
        "id": "oh3PmdkTfYGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "id": "FlZybpVuUw1A",
        "outputId": "c7f7a8e5-fc77-4a16-9415-a84d119a7e03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 2.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 2.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 1.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 2.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 2.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 2.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.63.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=768b41b36987e5240bd97a6e6eed3d647ee006a54cf10b500a6697e861c52bb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    x = trial.suggest_float('x', -10, 10)\n",
        "    return (x - 2) ** 2\n",
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(study.best_params) # E.g. {'x': 2.002108042}"
      ],
      "metadata": {
        "id": "aEdxFHEbbFyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "import sklearn.datasets\n",
        "import sklearn.ensemble\n",
        "import sklearn.model_selection\n",
        "import sklearn.svm\n",
        "\n",
        "\n",
        "# FYI: Objective functions can take additional arguments\n",
        "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
        "def objective(trial):\n",
        "    x, y = X_train,y_train\n",
        "\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"GradientBoostingClassifier\",\"LightGBM\"])\n",
        "    if classifier_name == \"GradientBoostingClassifier\":\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,16)\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
        "         classifier_obj = sklearn.ensemble.GradientBoostingClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "    else:\n",
        "         import lightgbm as lgb\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,16)\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,X_train.shape[1])\n",
        "         classifier_obj = lgb.LGBMClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "   \n",
        "         \n",
        "\n",
        "    accuracy=sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3).mean()\n",
        "   \n",
        "    return accuracy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "    print(study.best_trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkFEMF1VY6zF",
        "outputId": "0cbdfa1e-3fba-4bbf-d8ae-d7d546b5f468"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-03-12 22:47:06,622]\u001b[0m A new study created in memory with name: no-name-65a5b94c-4c6c-4b92-afb9-67099ef99400\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:11,287]\u001b[0m Trial 0 finished with value: 0.9438489168566289 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 3, 'max_features': 18}. Best is trial 0 with value: 0.9438489168566289.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:11,881]\u001b[0m Trial 1 finished with value: 0.9507090638196036 and parameters: {'classifier': 'LightGBM', 'max_depth': 6, 'max_features': 17}. Best is trial 1 with value: 0.9507090638196036.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:13,098]\u001b[0m Trial 2 finished with value: 0.9451337124858976 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 5, 'max_features': 7}. Best is trial 1 with value: 0.9507090638196036.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:13,642]\u001b[0m Trial 3 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 11}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:13,870]\u001b[0m Trial 4 finished with value: 0.9434204678420617 and parameters: {'classifier': 'LightGBM', 'max_depth': 4, 'max_features': 4}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:19,250]\u001b[0m Trial 5 finished with value: 0.9348476276496842 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 14, 'max_features': 14}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:21,535]\u001b[0m Trial 6 finished with value: 0.9472765089731672 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 9, 'max_features': 4}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:27,305]\u001b[0m Trial 7 finished with value: 0.9412782227692253 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 11, 'max_features': 18}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:27,968]\u001b[0m Trial 8 finished with value: 0.9339885239628171 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 5, 'max_features': 2}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:28,769]\u001b[0m Trial 9 finished with value: 0.9464201623584657 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 4, 'max_features': 5}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:29,314]\u001b[0m Trial 10 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 11}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:29,837]\u001b[0m Trial 11 finished with value: 0.9532803093214405 and parameters: {'classifier': 'LightGBM', 'max_depth': 16, 'max_features': 11}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:30,365]\u001b[0m Trial 12 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 10}. Best is trial 3 with value: 0.9545667591940085.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:30,883]\u001b[0m Trial 13 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:31,382]\u001b[0m Trial 14 finished with value: 0.9519944108633055 and parameters: {'classifier': 'LightGBM', 'max_depth': 10, 'max_features': 8}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:31,905]\u001b[0m Trial 15 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:32,381]\u001b[0m Trial 16 finished with value: 0.9511375128341709 and parameters: {'classifier': 'LightGBM', 'max_depth': 9, 'max_features': 14}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:32,771]\u001b[0m Trial 17 finished with value: 0.9528535145501728 and parameters: {'classifier': 'LightGBM', 'max_depth': 7, 'max_features': 14}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:33,303]\u001b[0m Trial 18 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:33,842]\u001b[0m Trial 19 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:34,299]\u001b[0m Trial 20 finished with value: 0.9507085124051705 and parameters: {'classifier': 'LightGBM', 'max_depth': 8, 'max_features': 7}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:34,807]\u001b[0m Trial 21 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:35,350]\u001b[0m Trial 22 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 12}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:35,856]\u001b[0m Trial 23 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:36,387]\u001b[0m Trial 24 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:36,875]\u001b[0m Trial 25 finished with value: 0.9519944108633055 and parameters: {'classifier': 'LightGBM', 'max_depth': 10, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:37,394]\u001b[0m Trial 26 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:37,918]\u001b[0m Trial 27 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:38,431]\u001b[0m Trial 28 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 12}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:38,948]\u001b[0m Trial 29 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:39,446]\u001b[0m Trial 30 finished with value: 0.9519944108633055 and parameters: {'classifier': 'LightGBM', 'max_depth': 10, 'max_features': 18}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:39,953]\u001b[0m Trial 31 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 8}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:40,485]\u001b[0m Trial 32 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:40,626]\u001b[0m Trial 33 finished with value: 0.9237068504420689 and parameters: {'classifier': 'LightGBM', 'max_depth': 2, 'max_features': 7}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:41,147]\u001b[0m Trial 34 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 6}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:41,692]\u001b[0m Trial 35 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 12}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:45,143]\u001b[0m Trial 36 finished with value: 0.9489908564458694 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 8, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:45,677]\u001b[0m Trial 37 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 10}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:46,199]\u001b[0m Trial 38 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 8}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:50,953]\u001b[0m Trial 39 finished with value: 0.9438483654421957 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 10, 'max_features': 17}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:56,722]\u001b[0m Trial 40 finished with value: 0.9292772390458767 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 15, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:57,248]\u001b[0m Trial 41 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:57,780]\u001b[0m Trial 42 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 12}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:58,290]\u001b[0m Trial 43 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 11}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:58,827]\u001b[0m Trial 44 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 11}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:59,313]\u001b[0m Trial 45 finished with value: 0.9511375128341709 and parameters: {'classifier': 'LightGBM', 'max_depth': 9, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:47:59,853]\u001b[0m Trial 46 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 17}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:04,042]\u001b[0m Trial 47 finished with value: 0.945134815314764 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 12, 'max_features': 8}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:04,572]\u001b[0m Trial 48 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 17}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:05,073]\u001b[0m Trial 49 finished with value: 0.9519944108633055 and parameters: {'classifier': 'LightGBM', 'max_depth': 10, 'max_features': 5}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:05,582]\u001b[0m Trial 50 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 10}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:06,124]\u001b[0m Trial 51 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:06,647]\u001b[0m Trial 52 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:07,169]\u001b[0m Trial 53 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 14}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:07,667]\u001b[0m Trial 54 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 18}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:08,196]\u001b[0m Trial 55 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 14}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:08,661]\u001b[0m Trial 56 finished with value: 0.9511375128341709 and parameters: {'classifier': 'LightGBM', 'max_depth': 9, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:09,187]\u001b[0m Trial 57 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 10}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:14,509]\u001b[0m Trial 58 finished with value: 0.9348476276496842 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 14, 'max_features': 14}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:15,019]\u001b[0m Trial 59 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:15,472]\u001b[0m Trial 60 finished with value: 0.9507085124051705 and parameters: {'classifier': 'LightGBM', 'max_depth': 8, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:15,983]\u001b[0m Trial 61 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:16,534]\u001b[0m Trial 62 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 11}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:17,057]\u001b[0m Trial 63 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 10}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:17,562]\u001b[0m Trial 64 finished with value: 0.9519944108633055 and parameters: {'classifier': 'LightGBM', 'max_depth': 10, 'max_features': 8}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:18,090]\u001b[0m Trial 65 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 12}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:18,606]\u001b[0m Trial 66 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:19,130]\u001b[0m Trial 67 finished with value: 0.9524228598778727 and parameters: {'classifier': 'LightGBM', 'max_depth': 15, 'max_features': 11}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:19,660]\u001b[0m Trial 68 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 7}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:19,930]\u001b[0m Trial 69 finished with value: 0.9498527172049024 and parameters: {'classifier': 'LightGBM', 'max_depth': 5, 'max_features': 6}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:20,451]\u001b[0m Trial 70 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 10}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:20,964]\u001b[0m Trial 71 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 2}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:21,487]\u001b[0m Trial 72 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 2}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:22,012]\u001b[0m Trial 73 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 4}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:22,837]\u001b[0m Trial 74 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 4}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:27,624]\u001b[0m Trial 75 finished with value: 0.93913266920979 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 13, 'max_features': 3}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:28,128]\u001b[0m Trial 76 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:28,662]\u001b[0m Trial 77 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:29,165]\u001b[0m Trial 78 finished with value: 0.9519944108633055 and parameters: {'classifier': 'LightGBM', 'max_depth': 10, 'max_features': 9}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:30,129]\u001b[0m Trial 79 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 12}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:30,357]\u001b[0m Trial 80 finished with value: 0.9434204678420617 and parameters: {'classifier': 'LightGBM', 'max_depth': 4, 'max_features': 2}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:30,888]\u001b[0m Trial 81 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 3}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:31,418]\u001b[0m Trial 82 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:31,942]\u001b[0m Trial 83 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 7}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:32,463]\u001b[0m Trial 84 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:33,008]\u001b[0m Trial 85 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 14}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:34,133]\u001b[0m Trial 86 finished with value: 0.9519944108633055 and parameters: {'classifier': 'LightGBM', 'max_depth': 10, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:41,257]\u001b[0m Trial 87 finished with value: 0.9404158105957592 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 12, 'max_features': 3}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:41,789]\u001b[0m Trial 88 finished with value: 0.9507090638196036 and parameters: {'classifier': 'LightGBM', 'max_depth': 6, 'max_features': 3}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:42,617]\u001b[0m Trial 89 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 16}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:43,996]\u001b[0m Trial 90 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 11}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:44,829]\u001b[0m Trial 91 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 4}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:45,770]\u001b[0m Trial 92 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 2}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:46,633]\u001b[0m Trial 93 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:47,476]\u001b[0m Trial 94 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 13}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:48,416]\u001b[0m Trial 95 finished with value: 0.9545667591940085 and parameters: {'classifier': 'LightGBM', 'max_depth': 13, 'max_features': 15}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:49,231]\u001b[0m Trial 96 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 17}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:49,954]\u001b[0m Trial 97 finished with value: 0.9541366559361418 and parameters: {'classifier': 'LightGBM', 'max_depth': 11, 'max_features': 17}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:50,486]\u001b[0m Trial 98 finished with value: 0.956281658081144 and parameters: {'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 2}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n",
            "\u001b[32m[I 2022-03-12 22:48:51,011]\u001b[0m Trial 99 finished with value: 0.9549957596230091 and parameters: {'classifier': 'LightGBM', 'max_depth': 14, 'max_features': 12}. Best is trial 13 with value: 0.956281658081144.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenTrial(number=13, values=[0.956281658081144], datetime_start=datetime.datetime(2022, 3, 12, 22, 47, 30, 367215), datetime_complete=datetime.datetime(2022, 3, 12, 22, 47, 30, 883332), params={'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 9}, distributions={'classifier': CategoricalDistribution(choices=('GradientBoostingClassifier', 'LightGBM')), 'max_depth': IntUniformDistribution(high=16, low=2, step=1), 'max_features': IntUniformDistribution(high=18, low=2, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=13, state=TrialState.COMPLETE, value=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Best Model\n",
        "print(study.best_params)"
      ],
      "metadata": {
        "id": "oKEwZpRvg2KC",
        "outputId": "890f38ac-7dd9-41ad-d4a7-d6d6393f3b4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'classifier': 'LightGBM', 'max_depth': 12, 'max_features': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Best Model Parameter to Test Data\n",
        "import lightgbm as lgb\n",
        "lgb_model = lgb.LGBMClassifier(random_state=17,max_depth= 12, max_features=9)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "# make predictions for test data\n",
        "accuracy_score(y_test, lgb_model.predict(X_test))"
      ],
      "metadata": {
        "id": "8cmstdAHg46W",
        "outputId": "0e3fed1a-aff8-46dc-b7d6-03fa5b7df29d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.956"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}